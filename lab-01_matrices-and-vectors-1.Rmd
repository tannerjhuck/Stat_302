---
title: "Lab 1"
author: "Tanner Huck"
date: "4/11/22"
output: html_document
---

<!--- Begin styling code. --->
<style type="text/css">
/* Whole document: */
body{
  font-family: "Palatino Linotype", "Book Antiqua", Palatino, serif;
  font-size: 12pt;
}
h1.title {
  font-size: 38px;
  text-align: center;
}
h4.author {
  font-size: 18px;
  text-align: center;
}
h4.date {
  font-size: 18px;
  text-align: center;
}
</style>
<!--- End styling code. --->

### Collaborators

Xiangyi Wen

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Instructions (4 points)

This lab will be worth 20 points, of which 4 can be earned by following instructions. Each item below is worth 1 point.

* Your code should be commented so that it is easy for us to follow.
* Your code should follow the style guidelines from Lecture Slides 1.
* Any reference to code results in text should be done using in-line R code. You should not be typing the actual numbers. Similarly, any values you are asked to calculate must be done using code. They should not be calculated by hand.
* Your document should look nice and be easy to read. Figures should be appropriately sized, headers and subheaders should be used, etc.

When generating data, I recommend viewing and exploring your data to get a sense of what it looks like using both R commands and the Editor tab in RStudio. 
This will help you confirm that what you generated is what you intended. 
It will also give you a sense of what the data look like, which can help decide how you want to present it.

*If you collaborated with anyone, you must include "Collaborated with: FIRSTNAME LASTNAME" at the top of your lab!*

## Part 1. Vectors (8 points)

Let's jump right in and start working with large simulations. You will need the functions `rnorm()` for Normally distributed simulations and `pnorm()` for the percentiles of the Normal distribution. This is all I am going to tell you about these functions, so you will need to use the documentation to help you with these questions! In order to open the documentation (for `rnorm()` for example) go into the console and type `?rnorm()`. 

**1a.** Create and store a vector of 100,000 simulations from a Normal distribution with mean 3 and standard deviation 5 (sometimes written as $N(3, 5^2)$). Print out only the first 5 elements of your vector using `head()`.

```{r, vector of 100,000 simulations}
#Making a vector x with 100,000 simulations with a mean of 3 and sd of 5
simulation <- c(rnorm(100000, 3, 5))
#Printing out the first 5 elements of vector x
head(simulation, 5)
```

**1b.** Generate 4 histograms. The histograms should include the first 50, 500, 5000, and 50000 elements of your simulations, respectively. Be sure to change the title of your histograms to write what they display in plain text. What do you notice about the histograms? Explain why you think this is.

(*Hint: look into the function `hist` to make a histogram and use the parameter `main` to change the title of your histogram*)
```{r histograms}
#Making 4 histograms of the simulation one for the first 50, 500, 5000, and 50000 elements
#Also changing creating a title for each histogram
hist(simulation[1:50], main = "Histogram of first 50 elements of simulation")
hist(simulation[1:500], main = "Histogram of first 500 elements of simulation")
hist(simulation[1:5000], main = "Histogram of first 5000 elements of simulation")
hist(simulation[1:50000], main = "Histogram of first 50000 elements of simulation")
```

As we are graphing more and more of our simulations, the graphs start to appear more and more evenly distributed. This is because the simulations are generated from a Normal distribution.

**1c.** Compute the mean and standard deviation of your vector from part a. Report them using in-line R code. 

```{r mean and sd of vector}
#Calculating the mean of the simulation vector
mean_simulation <- mean(simulation)
#Calculating the standard deviation of the simulation vector
sd_simulation <- sd(simulation)
```

The mean of our vector is `r mean_simulation` and the standard deviation is `r sd_simulation`. 

**1d.** In order to standardize vectors, we take each element and subtract the mean and then divide by the standard deviation (computed in part c). Create and store a new vector that is the standardization of your simulations from part (a). Create a histogram for all of these standardized simulations (don't forget to change the title again!). What do you notice?

(*Hint: don't use exactly 3 and 5 for the mean and standard deviation when standardizing. As a sanity check, after you standardize your vector, the mean should be exactly 0!*)

```{r standardization of vector}
# Creating the standardized vector by subtracting the mean and dividing each element by the sd and storing it in a new vector
standardized_simulation <- (simulation - mean_simulation) / sd_simulation  
# Making a histogram of all the standardized simulations
hist(standardized_simulation, main = "Histogram of all the standardized simulations")
```

This new graph of the standardized simulations appears to be evenly distributed around 0.

**1f.** Calculate (using an R function, see hint at the start of part 1) the percent of simulations from a $N(0, 1)$ that you *expect* to be above 1.644854. How does this compare to the observed proportion of your standardized simulations that are above 1.644854? 

(*Hint: pay attention to the parameter `lower.tail`. Additionally, to find the proportion of a vector above a certain value, you can use a combination of a logical comparison and the function `mean()`.*)

```{r calculating expected values}
# Calculating the percent of simulations we expect to see above 1.64484
simulation2 <- pnorm(1.644854, mean = 0, sd = 1, lower.tail = FALSE)
# Comparing this to the proportion of standardized simulations that are above 1.644854
percent_of_simulation <- mean(standardized_simulation > 1.644854)
```

The percent of simulations we expect to see above 1.644854 is about `r simulation2` and the observed proportion of standardized simulations that are above 1.644854 s about `r percent_of_simulation`.

**1g.** How does the percent of simulations from a $N(0, 1)$ that you *expect* to be above 1.644854 (from part f) compare to the observed proportion of your first **10** standardized simulations that are above 1.644854? Repeat this for your first **100**, **1000**, and **10,000** standardized simulations. 
What do you notice?

```{r comparing percents to standardized simulations}
# Calculating the proportion standardized simulations above 1.644854
# Once for the first 10, 100, 1000, 10000 simulations respectivily
first10StandardizedSimulations <- mean(standardized_simulation[1:10] > 1.644854)
first100StandardizedSimulations <- mean(standardized_simulation[1:100] > 1.644854)
first1000StandardizedSimulations <- mean(standardized_simulation[1:1000] > 1.644854)
first10000StandardizedSimulations <- mean(standardized_simulation[1:10000] > 1.644854)
```

As you include more and more of the data form the standardized simulation above 1.644854, the closer you get to the percent of simulations we expect to be above 1.644854.

## Part 2. Matrices (8 points)

A Binomial distribution with $n$ trials and probability of success $p$, sometimes shorthanded $Bin(n, p)$, represents the number of success out of $n$ independent trials, each with probability of success $p$. 
For this part, we will be using the Binomial distribution equivalent of the functions we used in part 1, specifically `rbinom()`.

**2a.** Initialize two empty matrices. One should have 10 rows and 4 columns, the other should have 10,000 rows and 4 columns. Be sure to give them informative names that follow style guidelines.

```{r empty matrices}
# Creating 2 empty matrices one 10 by 4 and one 10000 by 4
tenByFourMatrix <- matrix(NA, nrow = 10, ncol = 4)
tenThousandByFourMatrix <- matrix(NA, nrow = 10000, ncol = 4)
```

**2b.** Separately fill the first column of each matrix with independent draws from a Binomial distribution with probability $0.2$ and $n=5$. Repeat this process for the second through fourth columns using probabilities of $0.4$, $0.6$, and $0.8$, respectively. 

(*Hint: the $n$ in $Bin(n,p)$ notation is not necessarily the same as the `n` in  the `rbinom()` function. Read the documentation carefully!*)

```{r rbinom}
# Putting in values into the 2 matrices by using a Binomial distribution
# Each column has a different probability 0.2, 0.4,0.6, 0.8 respectively  
tenByFourMatrix[, 1] <- rbinom(10, 5, 0.2)
tenByFourMatrix[, 2] <- rbinom(10, 5, 0.4)
tenByFourMatrix[, 3] <- rbinom(10, 5, 0.6)
tenByFourMatrix[, 4] <- rbinom(10, 5, 0.8)
# For the larger matrix
tenThousandByFourMatrix[, 1] <- rbinom(10000, 5, 0.2)
tenThousandByFourMatrix[, 2] <- rbinom(10000, 5, 0.4)
tenThousandByFourMatrix[, 3] <- rbinom(10000, 5, 0.6)
tenThousandByFourMatrix[, 4] <- rbinom(10000, 5, 0.8)
```

**2c.** Use four well-labeled histograms to plot the values of each column (if you want to change the number of bars you can use the `breaks` parameter). Discuss what you see.

```{r more histograms}
# Creating histograms for each column of the 2 matrices
hist(tenByFourMatrix[, 1], main = "10 elements of Binomial distribution with probability 0.2 and 5 trials")
hist(tenByFourMatrix[, 2], main = "10 elements of Binomial distribution with probability 0.4 and 5 trials")
hist(tenByFourMatrix[, 3], main = "10 elements of Binomial distribution with probability 0.6 and 5 trials")
hist(tenByFourMatrix[, 4], main = "10 elements of Binomial distribution with probability 0.8 and 5 trials")
hist(tenThousandByFourMatrix[, 1], main = "100000 elements of Binomial distribution with probability 0.2 and 5 trials")
hist(tenThousandByFourMatrix[, 2], main = "100000 elements of Binomial distribution with probability 0.4 and 5 trials")
hist(tenThousandByFourMatrix[, 3], main = "100000 elements of Binomial distribution with probability 0.6 and 5 trials")
hist(tenThousandByFourMatrix[, 4], main = "100000 elements of Binomial distribution with probability 0.8 and 5 trials")
```

**2d.** Calculate the column means of both matrices and present these results in a single table. The rows and columns of your tables should be easy to read and interpret. I suggest using `kableExtra` 

```{r means and tables}
# Making a table with the col means 
library(knitr)
library(kableExtra)
twoByFourMatrix <- matrix(c(mean(tenByFourMatrix[, 1]),
                      mean(tenByFourMatrix[, 2]),
                      mean(tenByFourMatrix[, 3]),
                      mean(tenByFourMatrix[, 4]),
                      mean(tenThousandByFourMatrix[, 1]),
                      mean(tenThousandByFourMatrix[, 2]),
                      mean(tenThousandByFourMatrix[, 3]),
                      mean(tenThousandByFourMatrix[, 4])),
                      nrow = 2, ncol = 4, byrow = TRUE)
colnames(twoByFourMatrix) <- c("1st Col", "2nd Col", "3rd Col", "4th Col")
rownames(twoByFourMatrix) <- c("Size 10", "Size 10000")
kable_styling(kable(twoByFourMatrix))
```

**2e.** What is the *expected* column mean for each column? Which matrix has observed column means that are closer to this expectation? Why do you think that is?

(*Hint: the expected value of a draw from a $Bin(n,p)$ distribution is $n\times p$*)

```{r expected means}
expectedColMean <- c(5 * 0.2, 5 * 0.4, 5 * 0.6, 5 * 0.8)
```

As the number of observations increases, we get closer to the expected column means.

**2f.** What is the *expected* variance for the values in each column? Which matrix has observed column sample variances that are closer to these values? Why do you think that is?

(*Hint: the expected value of a draw from a $Bin(n,p)$ distribution is $n\times p\times(1-p)$*)

```{r expected variance}
# Calculating the variance  for each column
variance_twoByFourMatrix <- matrix(c(var(tenByFourMatrix[, 1]),
                      var(tenByFourMatrix[, 2]),
                      var(tenByFourMatrix[, 3]),
                      var(tenByFourMatrix[, 4]),
                      var(tenThousandByFourMatrix[, 1]),
                      var(tenThousandByFourMatrix[, 2]),
                      var(tenThousandByFourMatrix[, 3]),
                      var(tenThousandByFourMatrix[, 4])),
                      nrow = 2, ncol = 4, byrow = TRUE)
```

The larger 10000 by 4 matrix has column sample variances closer to the expected values. This is because it has significantly more observations, the varience will be closer to the expected value when there are more observations.

